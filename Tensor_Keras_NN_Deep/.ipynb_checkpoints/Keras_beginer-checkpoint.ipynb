{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras Model module\n",
    "#Sequential Model type from Keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense , Dropout , Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will import CNN layers from keras , These are the convolutional layers that will help us efficiently train on image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D , MaxPool2D, Conv2D\n",
    "#These are the convulutional layers that will help us efficiently train on image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finallly we will import some utilities. This will help us transform our data later:\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data from MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#load pre-shuffled MNIST data into train and test sets\n",
    "(x_train, y_train) , (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can look at the shape of the dataset\n",
    "x_train.shape ,x_test.shape ,  y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Great, so it appears that we have 60000 samples in our training set, and the images are 28 px X 28 px. \n",
    "# We can confirm this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c3e00fff88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In generally, when working with Computer vision, it's helpful to visually plot the data befor doing any allgorithm work.\n",
    "#can easily avoid mistakes such as misinterpreting the data dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing input data for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow backend\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)\n",
    "x_test = x_test.reshape(x_test.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to confirm , we can print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#The final Preprocessing step for the input data is to convert our data type to float32 \n",
    "#and normalize our data values to the range[0,1]\n",
    "print(type(x_train))\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now our datas are ready for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "#shape of our class label data\n",
    "print(y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We should have 10 different classes, one for each digit, but it looks like we only have a 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets fix the above problem\n",
    "y_train = np_utils.to_categorical(y_train,10) #10 digits\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're ready to define our model architecture. In actual R&D work, researchers will spend a considerable\n",
    "#amount of time studying model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Keras Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the input layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-501b960e8a21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#CNN input layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Conv2D' is not defined"
     ]
    }
   ],
   "source": [
    "#CNN input layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import scipy \n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8.0\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "print(IPython.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "print(theano.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
